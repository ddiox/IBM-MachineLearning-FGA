# -*- coding: utf-8 -*-
"""BBC Text Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yDfAYTt09OoSGlOqonEvgoSOz55kTvxi

Submission 1 Membuat Model NLP dengan TensorFlow

BBC Text Classification

# Download dataset
"""

!wget --no-check-certificate \
  https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv \
  -O /tmp/bbc-text.csv

"""# Read dataset"""

import pandas as pd

df = pd.read_csv('/tmp/bbc-text.csv')

df.head()

df['category'].value_counts()

"""# One-hot encoding"""

category = pd.get_dummies(df.category)
df_new = pd.concat([df, category], axis=1)
df_new = df_new.drop(columns='category')
df_new

"""# Data Preparation"""

# Converting to numpy array
text = df_new['text'].values
label = df_new[['business', 'entertainment', 'politics', 'sport', 'tech']].values

# Split the dataset, where validation set is equal to 0.2
from sklearn.model_selection import train_test_split
text_train, text_test, label_train, label_test = train_test_split(text, label, test_size=0.2)

# Tokenization
from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer(num_words=5000, oov_token='-')
tokenizer.fit_on_texts(text_train) 
tokenizer.fit_on_texts(text_test)

# Sequence and Padding
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
sequence_train= tokenizer.texts_to_sequences(text_train)
sequence_test = tokenizer.texts_to_sequences(text_test)
 
padded_train = pad_sequences(sequence_train)
padded_test = pad_sequences(sequence_test)

"""# Building Model"""

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.9):
      print("\nAccuracy >90%!")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(padded_train, label_train, epochs=50, callbacks=[callbacks],
                    validation_data=(padded_test, label_test), verbose=2)